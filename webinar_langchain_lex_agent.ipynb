{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jairodriguez/AgentGPT/blob/main/webinar_langchain_lex_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGSj8heFreA"
      },
      "source": [
        "# Ask Lex Agent\n",
        "\n",
        "**Note**: This notebook is not free to run, you will need to create ~20K OpenAI `text-embedding-ada-002` embedding which do cost money. The Pinecone index can be run within the free tier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pADty8WtkcGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d518bf-ca98-4638-e134-441d9d0e6b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.5/578.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.2/443.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.0/223.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.0/218.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.0/218.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.3 which is incompatible.\n",
            "tensorflow-hub 0.13.0 requires protobuf>=3.19.6, but you have protobuf 3.19.3 which is incompatible.\n",
            "tensorboard 2.12.2 requires protobuf>=3.19.6, but you have protobuf 3.19.3 which is incompatible.\n",
            "google-cloud-translate 3.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.3 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.3 which is incompatible.\n",
            "google-cloud-firestore 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.3 which is incompatible.\n",
            "google-cloud-datastore 2.15.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.3 which is incompatible.\n",
            "google-cloud-bigquery 3.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.3 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.3 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU datasets pinecone-client[grpc] langchain openai tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYzuZiAP5HGL"
      },
      "source": [
        "Set api keys, etc:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1R8X32-41vc"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"OPENAI_API_KEY\"  # platform.openai.com\n",
        "PINECONE_API_KEY = \"PINECONE_API_KEY\"  # app.pinecone.io\n",
        "PINECONE_ENV = \"PINECONE_ENV\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RYCg6ep4L0p"
      },
      "source": [
        "First we download a prebuilt Lex Fridman podcast transcriptions dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "e87699c385784c85854e1054b5968571",
            "5a9c499bf327431b901e0b5e0a550216",
            "0695335820ce455180bd419e07dcf5db",
            "d88f2f2b43ab4d2a8d771fa79150e825",
            "bebf96067c4b4c0c89fe48ffd298af2e",
            "99285af984a148468958a98d3094ea7c",
            "fd11657b1bf34070a4cd3cf8ae91b061",
            "9b7cf8aa612d451b81422614ed7d3573",
            "4a2d157e6eaf4e6791d09393d88717a2",
            "8cee9c02a0d64f34b3658bee64ab7c85",
            "20cfb511a75248f39c1b2c55ec0171b4",
            "c486860f3e9c4bd89cb1248e4baf1487",
            "34064b2e313d4c41abe7cd97822753f2",
            "6e8b276542014087aeedbc110f0765ab",
            "a98951120f8b49e09d813e209d1a06d2",
            "ff7b73999de747ca9c76b8513536a7f8",
            "ebf7c349b573426886af0f0d10b1d7a8",
            "08122c715c4f4d4d916b6869fc118558",
            "ae4c73f09f70440784ece901c8c65bc6",
            "5a125807e11145a6826d2f3f51ecc7e9",
            "c796affa0a76436e854c1504c427fcdd",
            "1880b4cf87ac48249f349df9eaa24849",
            "939daffe13fa4204996d2ce759cb5a22",
            "a73639e72818450ca867dfea800f5dc6",
            "9c58f8c8f4244a868ceba8ef78063745",
            "f249a856c07e48738299bd2c4b2839ac",
            "0bb226ac54a24992aa9a9fddab821737",
            "7c3507c643f74c219f4f27c59a06e1a6",
            "462e2d82704c46fab99be483e1aa8093",
            "7faea7f7337449f186a1ff6105fda39a",
            "b34785bb93a44c81b621553f54f4a64d",
            "5af9e0f7596c4b87877b730a3d074279",
            "725019bcae14422b9b3542fcd52901db",
            "c2fb2ac93f23460c809ffb46db60911f",
            "7c1bac7841234d62ad0826c6153d6f3c",
            "760679f729ee4270aec5cf59796ef7b0",
            "4630fe01eaf74fbdb68a63051fb1b15b",
            "55ec47746e5c467f97de8fc33afb09e8",
            "cada6880d46a4e06b61960d511a6eedd",
            "4ff4eec0986246a8a4b38caf6f76e963",
            "6a5a697ce41a45fd9bedb783127aeae0",
            "70cda74457054f9cab1e78f6880267fd",
            "65bf96b0718245519038e19fd548f161",
            "bca21b90d06e423c85587280747854cb"
          ]
        },
        "id": "2AT6IR3t4Rcl",
        "outputId": "19496cf0-53ed-4f7a-f6a4-26e76f46c921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset json/jamescalam--lex-transcripts to /root/.cache/huggingface/datasets/jamescalam___json/jamescalam--lex-transcripts-6a9688b7915283fe/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e87699c385784c85854e1054b5968571"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/44.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c486860f3e9c4bd89cb1248e4baf1487"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "939daffe13fa4204996d2ce759cb5a22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2fb2ac93f23460c809ffb46db60911f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/jamescalam___json/jamescalam--lex-transcripts-6a9688b7915283fe/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['video_id', 'channel_id', 'title', 'published', 'transcript', 'source'],\n",
              "    num_rows: 499\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(\n",
        "    'jamescalam/lex-transcripts',\n",
        "    split='train'\n",
        ")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG7-U4xC4rcE"
      },
      "source": [
        "Initialize the `indexer` object."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXhL1PnkfOLV",
        "outputId": "51cd14e5-28f6-4ea7-e7bc-5998539ad8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'video_id': '_SpptYg_0Rs',\n",
              " 'channel_id': 'UCSHZKyawb77ixDdsGog4iWA',\n",
              " 'title': 'Are We Living in a Simulation? with George Hotz and Lex Fridman | AI Podcast Clips',\n",
              " 'published': datetime.datetime(2019, 8, 29, 13, 9, 2),\n",
              " 'transcript': \" Do you think we're living in a simulation? Yes, but it may be unfalsifiable. What do you mean by unfalsifiable? So if the simulation is designed in such a way that they did like a formal proof to show that no information can get in and out, and if their hardware is designed for anything in the simulation to always keep the hardware in spec, it may be impossible to prove whether we're in a simulation or not. So they've designed it such that it's a closed system, you can't get outside the system? Well maybe it's one of three worlds. We're either in a simulation which can be exploited, we're in a simulation which not only can't be exploited, but like the same thing is true about VMs. A really well designed VM, you can't even detect if you're in a VM or not. That's brilliant. So we're, yeah, so the simulation is running on a virtual machine. But now in reality, all VMs have ways to detect. That's the point. I mean, is it, you've done quite a bit of hacking yourself, and so you should know that really any complicated system will have ways in and out. So this isn't necessarily true going forward. I spent my time away from Kama, I learned Coq, it's a dependently typed, like, it's a language for writing math proofs. And if you write code that compiles in a language like that, it is correct by definition. The types check its correctness. So it's possible that the simulation is written in a language like this, in which case, you know. Yeah, but that can't be sufficiently expressive a language like that. Oh, it can. It can be? Oh, yeah. Okay. Well, so, all right, so. The simulation doesn't have to be Turing complete if it has a scheduled end date. Looks like it does, actually, with entropy. I mean, I don't think that a simulation that results in something as complicated as the universe would have a form of proof of correctness, right? It's possible, of course. We have no idea how good their tooling is, and we have no idea how complicated the universe computer really is. It may be quite simple. It's just very large, right? It's definitely very large. But the fundamental rules might be super simple. Yeah, Conway's Game of Life kind of stuff. So if you could hack, so imagine a simulation that is hackable, if you could hack it, what would you change about the universe? How would you approach hacking a simulation? The reason I gave that talk... By the way, I'm not familiar with the talk you gave. I just read that you talked about escaping the simulation or something like that. So maybe you can tell me a little bit about the theme and the message there, too. It wasn't a very practical talk about how to actually escape a simulation. It was more about a way of restructuring an us versus them narrative. If we continue on the path we're going with technology, I think we're in big trouble as a species, and not just as a species, but even as me as an individual member of the species. So if we could change rhetoric to be more like to think upwards, like to think about that we're in a simulation and how we could get out, already we'd be on the right path. What you actually do once you do that, well, I assume I would have acquired way more intelligence in the process of doing that. So I'll just ask that. So the thinking upwards, what kind of breakthrough ideas do you think thinking in that way could inspire? And why did you say upwards? Upwards. Into space? Are you thinking sort of exploration in all forms? The space narrative that held for the modernist generation doesn't hold as well for the post-modern generation. What's the space narrative? Are we talking about the same space? The three-dimensional space? No, no, space, like going up to space. Literally space, yeah. Like building, like Elon Musk, like we're going to build rockets, we're going to go to Mars, we're going to colonize the universe. And the narrative you're referring, I was born in the Soviet Union, you're referring to the race to space. The race to space, yes. The space to explore, okay. That was a great modernist narrative. It doesn't seem to hold the same weight in today's culture. I'm hoping for good post-modern narratives that replace it. So let's think, so you work a lot with AI. So AI is one formulation of that narrative. There could be also, I don't know how much you do in VR and AR. That's another, I know less about it, but every time I play with it in our research, it's fascinating, that virtual world. Are you interested in the virtual world? I would like to move to virtual reality. In terms of your work? No, I would like to physically move there. The apartment I can rent in the cloud is way better than the apartment I can rent in the real world. Well, it's all relative, isn't it? Because others will have very nice apartments too, so you'll be inferior in the virtual world as well. But that's not how I view the world, right? I don't view the world, I mean, that's a very like almost zero-sum-ish way to view the world. Say like my great apartment isn't great because my neighbor has one too. No, my great apartment is great because like, look at this dishwasher, man. You just touch the dish and it's washed, right? And that is great in and of itself if I have the only apartment or if everybody had the apartment, I don't care. So you have fundamental gratitude.\",\n",
              " 'source': 'https://youtu.be/_SpptYg_0Rs'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chunks of text in the `transcript` field can be very long so we first need to split these into smaller chunks. To count the size of these chunks we need to count the number of `text-embedding-ada-002` tokens. We can do that using the `tiktoken` tokenizer:"
      ],
      "metadata": {
        "id": "mTVXz6IrlZig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')  # cl100k base is encoder used by ada-002\n",
        "\n",
        "# define a length function\n",
        "def tiktoken_len(text: str) -> int:\n",
        "    tokens = tokenizer.encode(text, disallowed_special=())\n",
        "    return len(tokens)"
      ],
      "metadata": {
        "id": "rXIHlnFOljmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiktoken_len(\"here is a random sentence we can get the token length for\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Br4lPWNmZYy",
        "outputId": "ca52de79-79e8-4ea5-fada-d65523fac523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use that to initialize a LangChain text splitter:"
      ],
      "metadata": {
        "id": "iXq1FdedmeSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=20,  # number of tokens overlap between chunks\n",
        "    length_function=tiktoken_len,  # token count function\n",
        "    separators=['\\n\\n', '.\\n', '\\n', '.', '?', '!', ' ', '']\n",
        ")"
      ],
      "metadata": {
        "id": "n7W6tZz4mji-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All we need to do now is iterate through the dataset and split the longer transcripts into smaller chunks using the `text_splitter`."
      ],
      "metadata": {
        "id": "XoCTfxEgm2XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "new_data = []\n",
        "\n",
        "for row in tqdm(data):\n",
        "    chunks = text_splitter.split_text(row['transcript'])\n",
        "    row.pop('transcript')\n",
        "    for i, text in enumerate(chunks):\n",
        "        new_data.append({**row, **{'chunk': i, 'text': text}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "be88b55eb0d9440897d10bf20942248f",
            "d6411033f2f341c58711f959d745f1db",
            "ea1e5c07ab1440b8a9fd5ee0d93b9683",
            "0ef2acfbf7094bee8e24b00b4b8fc017",
            "3e7c7d154a024fccba4b2c1ca3a83766",
            "5f123fa8d7fa4997a867509f74700d9c",
            "5fce9695eeb24ee385aa908345e02f3b",
            "3b8dde14b3d142778db150e58af5e9b6",
            "1640ac698e204533b25f385549a2d037",
            "62a49ced78ae4b168d1679ea9a02a3bc",
            "977462f15f1d4c27a3270c2b7c9f4fc4"
          ]
        },
        "id": "YB-z5RRJm-05",
        "outputId": "fa17c637-6a66-47a4-c7ff-c4171bc2e1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/499 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be88b55eb0d9440897d10bf20942248f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQyXKpevn2U2",
        "outputId": "39cfd223-03e0-460b-ba46-a596424c4846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'video_id': '_SpptYg_0Rs',\n",
              " 'channel_id': 'UCSHZKyawb77ixDdsGog4iWA',\n",
              " 'title': 'Are We Living in a Simulation? with George Hotz and Lex Fridman | AI Podcast Clips',\n",
              " 'published': datetime.datetime(2019, 8, 29, 13, 9, 2),\n",
              " 'source': 'https://youtu.be/_SpptYg_0Rs',\n",
              " 'chunk': 0,\n",
              " 'text': \"Do you think we're living in a simulation? Yes, but it may be unfalsifiable. What do you mean by unfalsifiable? So if the simulation is designed in such a way that they did like a formal proof to show that no information can get in and out, and if their hardware is designed for anything in the simulation to always keep the hardware in spec, it may be impossible to prove whether we're in a simulation or not. So they've designed it such that it's a closed system, you can't get outside the system? Well maybe it's one of three worlds. We're either in a simulation which can be exploited, we're in a simulation which not only can't be exploited, but like the same thing is true about VMs. A really well designed VM, you can't even detect if you're in a VM or not. That's brilliant. So we're, yeah, so the simulation is running on a virtual machine. But now in reality, all VMs have ways to detect. That's the point. I mean, is it, you've done quite a bit of hacking yourself, and so you should know that really any complicated system will have ways in and out. So this isn't necessarily true going forward. I spent my time away from Kama, I learned Coq, it's a dependently typed, like, it's a language for writing math proofs\"}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7loADj1n5uZ",
        "outputId": "5a0177c2-7f16-4b15-ae87-d2be157f5f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'video_id': '_SpptYg_0Rs',\n",
              " 'channel_id': 'UCSHZKyawb77ixDdsGog4iWA',\n",
              " 'title': 'Are We Living in a Simulation? with George Hotz and Lex Fridman | AI Podcast Clips',\n",
              " 'published': datetime.datetime(2019, 8, 29, 13, 9, 2),\n",
              " 'source': 'https://youtu.be/_SpptYg_0Rs',\n",
              " 'chunk': 1,\n",
              " 'text': \"And if you write code that compiles in a language like that, it is correct by definition. The types check its correctness. So it's possible that the simulation is written in a language like this, in which case, you know. Yeah, but that can't be sufficiently expressive a language like that. Oh, it can. It can be? Oh, yeah. Okay. Well, so, all right, so. The simulation doesn't have to be Turing complete if it has a scheduled end date. Looks like it does, actually, with entropy. I mean, I don't think that a simulation that results in something as complicated as the universe would have a form of proof of correctness, right? It's possible, of course. We have no idea how good their tooling is, and we have no idea how complicated the universe computer really is. It may be quite simple. It's just very large, right? It's definitely very large. But the fundamental rules might be super simple. Yeah, Conway's Game of Life kind of stuff. So if you could hack, so imagine a simulation that is hackable, if you could hack it, what would you change about the universe? How would you approach hacking a simulation? The reason I gave that talk... By the way, I'm not familiar with the talk you gave. I just read that you talked about escaping the simulation or something like that\"}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to encode all of these records and store them in a vector DB for later retrieval. To initialize the embedding model we can do:"
      ],
      "metadata": {
        "id": "6dTbcu-sfcXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "UXOB9XkefemC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to initialize the vector DB where we'll be storing the embeddings we do:"
      ],
      "metadata": {
        "id": "yI7WJaddodkM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y338927dkxlY"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # app.pinecone.io\n",
        "    environment=PINECONE_ENV  # next to API key in console\n",
        ")\n",
        "\n",
        "index_name = \"pod-gpt\"\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name, dimension=1536\n",
        "    )\n",
        "\n",
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we loop through and populate our new index:"
      ],
      "metadata": {
        "id": "JwKhmUCOfjUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "for i in tqdm(range(0, len(new_data), batch_size)):\n",
        "    # get end of batch\n",
        "    i_end = min(len(new_data), i+batch_size)\n",
        "    # get batch of records\n",
        "    metadatas = new_data[i:i_end]\n",
        "    ids = [f\"{meta['video_id']}-{meta['chunk']}\" for meta in metadatas]\n",
        "    texts = [meta['text'] for meta in metadatas]\n",
        "    xc = embeddings.embed_documents(texts)\n",
        "    to_upsert = zip(ids, xc, metadatas)\n",
        "    # now add to Pinecone vec DB\n",
        "    index.upsert(vectors=to_upsert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "eab50425900f483dbef0cb6bd6dafead",
            "065b9a3097e34345a35d2e8a7619e2ee",
            "c874185706134ceb9157fe1329f8d9f8",
            "617bd3409ca945fa83425406578c8ba2",
            "2219b3e11ce644468d57655895bef37a",
            "0867a1f242bb465a8df0d459d35a33e1",
            "6205d5a2e2804a1e9a9d78d94afb4d00",
            "d6dcf823e58345839271b90b42b66565",
            "20264f594aaa4f00aa3f03b3888b1e2e",
            "a06ca00714734a9e96abaf6795577a7a",
            "dc854970983741819915a88bb8254bde"
          ]
        },
        "id": "q6jE4GpifmcL",
        "outputId": "4922f45c-071b-460d-840c-ee26537f4f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/362 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eab50425900f483dbef0cb6bd6dafead"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFTiO7eX2mkN"
      },
      "source": [
        "Our vector index is populated and we can move onto the query and interaction with the agent. For this we actually reinitialize the vector db component *via LangChain*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPvqFFGXcFGF"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "vectordb = Pinecone(\n",
        "    index=index,\n",
        "    embedding_function=embeddings.embed_query,\n",
        "    text_key=\"text\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPFXYJE92mNm"
      },
      "source": [
        "Initialize `gpt-3.5-turbo` chat model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jESRtKeJk1IO"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm=ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7isHNe1Gtp_"
      },
      "source": [
        "We then initialize the QA retrieval object using our `llm` and the `vectordb.as_retriever()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkTHIAE47uJp"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtaTKxTJG7J8"
      },
      "source": [
        "One additional thing we have here is the `chain_type=\"stuff\"`. There are two options here, `\"stuff\"` or `\"map_reduce\"`. The `map_reduce` option essentially summarizes returned documents, whereas the `stuff` option just returns the retrieved documents as is.\n",
        "\n",
        "The `retriever` is ready and can be used by us like this. However, we need to convert it into a `Tool` to be used by our conversational agent. To do that we need the `retriever` itself, a tool description, and a tool name. We use these to initialize the tool like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEQEdRQRmCbO"
      },
      "outputs": [],
      "source": [
        "tool_desc = \"\"\"Use this tool to answer user questions using Lex\n",
        "Fridman podcasts. If the user states 'ask Lex' use this tool to get\n",
        "the answer. This tool can also be used for follow up questions from\n",
        "the user.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abClSi8GlC8O"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "tools = [Tool(\n",
        "    func=retriever.run,\n",
        "    description=tool_desc,\n",
        "    name='Lex Fridman DB'\n",
        ")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9o6IIHSHwVX"
      },
      "source": [
        "With that, we're ready to initialize the conversational agent. As it is a *conversational* agent, it does need some form of [conversational memory](https://www.pinecone.io/learn/langchain-conversational-memory/). For this we will use the `ConversationBufferWindowMemory` option, which will *remember* the previous `k` interactions between the user and the AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_CRqHPrmcHo"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",  # important to align with agent prompt (below)\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArdEDGH7nBRR"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description', \n",
        "    tools=tools, \n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=2,\n",
        "    early_stopping_method=\"generate\",\n",
        "    memory=memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8EkS7lG3ElB"
      },
      "source": [
        "Important items in `agent` parameter:\n",
        "\n",
        "* `chat-conversational`: for chatbots with conversational memory.\n",
        "* `react`: refers to the ReAct framework.\n",
        "* `description`: because the LLM relies on the tool description to decide which tool to use.\n",
        "\n",
        "### Conversational Agent Prompt\n",
        "\n",
        "The prompt of the conversational agent is fairly complex. Let's create it then break it down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1ApK_bkBOQ7",
        "outputId": "106b7516-4a13-4cbf-d895-01d22dd31e7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me please, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "conversational_agent.agent.llm_chain.prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISOscagrnDyD"
      },
      "outputs": [],
      "source": [
        "sys_msg = \"\"\"You are a helpful chatbot that answers the user's questions.\n",
        "\"\"\"\n",
        "\n",
        "prompt = conversational_agent.agent.create_prompt(\n",
        "    system_message=sys_msg,\n",
        "    tools=tools\n",
        ")\n",
        "conversational_agent.agent.llm_chain.prompt = prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezpd5vaOMC-w"
      },
      "source": [
        "We can see the prompt template like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvEAE9XKMFIR",
        "outputId": "e72613f3-dbac-4a60-ac92-4f8fa7e45d06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template=\"You are a helpful chatbot that answers the user's questions.\\n\", template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me please, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "conversational_agent.agent.llm_chain.prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56MZZYTTs0Jq"
      },
      "source": [
        "The conversational agent prompt is defined by the `ChatPromptTemplate`. Let's break it down:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ybUWUOZOFAL",
        "outputId": "b69d8a2e-e880-418c-a65c-e66136d04f61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input', 'chat_history', 'agent_scratchpad']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "conversational_agent.agent.llm_chain.prompt.input_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axHAsgRROFUO"
      },
      "source": [
        " This prompt template contains *three* `input_variables`, those are:\n",
        "\n",
        "* `input`: The new user input to the chatbot, i.e. our prompt/query.\n",
        "\n",
        "* `chat_history`: We defined this above in the `ConversationBufferWindowMemory` definition.\n",
        "\n",
        "* `agent_scratchpad`: This is where we store the thoughts of the LLM as it is deciding which tools to interact with and *how* to interact with them.\n",
        "\n",
        "These `input_variables` are fed into the `messages` contained within the prompt template, let's see what we have there:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3z2E1rlOIr_",
        "outputId": "b5b65215-7224-4b37-ba67-d9591bddc58e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template=\"You are a helpful chatbot that answers the user's questions.\\n\", template_format='f-string', validate_template=True), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='chat_history'),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me please, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "conversational_agent.agent.llm_chain.prompt.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuMfxYayOIbu"
      },
      "source": [
        "\n",
        "It's a little hard to see here, but there are **three** components in `messages`. Those are:\n",
        "\n",
        "* `SystemMessagePromptTemplate`\n",
        "\n",
        "* `MessagesPlaceholder`\n",
        "\n",
        "* `HumanMessagePromptTemplate`\n",
        "\n",
        "Let's start with the first item, the `SystemMessage`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9JWEqIzs9oC",
        "outputId": "d570f767-a1a5-484c-8911-7529bd89322c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template=\"You are a helpful chatbot that answers the user's questions.\\n\", template_format='f-string', validate_template=True), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "conversational_agent.agent.llm_chain.prompt.messages[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2MkeX4_tIga",
        "outputId": "dd118101-6bd6-4675-8d72-e0c431d9d741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a helpful chatbot that answers the user's questions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    conversational_agent.agent.llm_chain.prompt.messages[0].prompt.template\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pill7M9AtdIJ"
      },
      "source": [
        "That is our initial system message that we set earlier with the `sys_msg`. There's not much to say about this other than it is used to \"prime\" (set the initial objective of) the model.\n",
        "\n",
        "Next we have the `MessagesPlaceholder`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHeZW75itky1",
        "outputId": "997ca023-8e59-4968-aa04-def84e9e2b65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MessagesPlaceholder(variable_name='chat_history')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "conversational_agent.agent.llm_chain.prompt.messages[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89ktagFTSkvv"
      },
      "source": [
        "We can see from `'chat_history'` (this must align to the `memory_key` from the `ConversationBufferWindowMemory` initialized earlier) that this is where the previous messages of the conversation will be fed into the LLM.\n",
        "\n",
        "The format of this input is set by the type of conversational memory being used, which in this case is the `ConversationBufferWindowMemory`.\n",
        "\n",
        "Finally, we have the `HumanMessagePromptTemplate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcIVdeklTZwh",
        "outputId": "fd18fd45-17fd-4a15-d13b-b20784100b13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> Lex Fridman DB: Use this tool to answer user questions using Lex\\nFridman podcasts. If the user states \\'ask Lex\\' use this tool to get\\nthe answer. This tool can also be used for follow up questions from\\nthe user.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me please, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string \\\\ The action to take. Must be one of Lex Fridman DB\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "conversational_agent.agent.llm_chain.prompt.messages[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRuqI-sCTZsb",
        "outputId": "60f1218a-f11a-4c60-b556-4cc51d476477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOOLS\n",
            "------\n",
            "Assistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\n",
            "\n",
            "> Lex Fridman DB: Use this tool to answer user questions using Lex\n",
            "Fridman podcasts. If the user states 'ask Lex' use this tool to get\n",
            "the answer. This tool can also be used for follow up questions from\n",
            "the user.\n",
            "\n",
            "RESPONSE FORMAT INSTRUCTIONS\n",
            "----------------------------\n",
            "\n",
            "When responding to me please, please output a response in one of two formats:\n",
            "\n",
            "**Option 1:**\n",
            "Use this if you want the human to use a tool.\n",
            "Markdown code snippet formatted in the following schema:\n",
            "\n",
            "```json\n",
            "{{\n",
            "    \"action\": string \\ The action to take. Must be one of Lex Fridman DB\n",
            "    \"action_input\": string \\ The input to the action\n",
            "}}\n",
            "```\n",
            "\n",
            "**Option #2:**\n",
            "Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n",
            "\n",
            "```json\n",
            "{{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": string \\ You should put what you want to return to use here\n",
            "}}\n",
            "```\n",
            "\n",
            "USER'S INPUT\n",
            "--------------------\n",
            "Here is the user's input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\n",
            "\n",
            "{input}\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    conversational_agent.agent.llm_chain.prompt.messages[2].prompt.template\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3NhHdrMTia2"
      },
      "source": [
        "This is the most interesting component. First, we have a single `input` — the user's query/prompt. But before this we see a lot of text, the majority of this is the setup for the LLM to be able to use any tools that we've passed to the conversational agent.\n",
        "\n",
        "In our case, there is just one tool, the `Lex Fridman DB` tool that we defined earlier. We can also see the tool description that we defined. The LLM will use this tool description to figure out which tool (if any) it should use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo3nDYEWUQLZ"
      },
      "source": [
        "## Having a Conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyiFqLg5UPyM"
      },
      "source": [
        "Let's begin our conversation. We'll start as any typical conversation begins:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwjREzM8nJsx",
        "outputId": "4e98327f-9195-4cd0-f01a-b88cbae92b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"I'm just a chatbot, so I don't have feelings, but I'm here to help you with any questions you have!\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'hi how are you',\n",
              " 'chat_history': [],\n",
              " 'output': \"I'm just a chatbot, so I don't have feelings, but I'm here to help you with any questions you have!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "conversational_agent(\"hi how are you\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGM7i372Ua7X"
      },
      "source": [
        "Looks good. We should note that there is this **AgentExecutor chain** thing. Where we can see an `\"action\"` and an `\"action_input\"`. It is here where the agent is deciding whether it should use a tool.\n",
        "\n",
        "Here we see the agent decides on `\"action\": \"Final Answer\"`, meaning no tool is required. Therefore, it just uses the LLM as per usual to generate an answer. That answer can be seen in `\"I'm just a chatbot, I don't have feelings, but thanks for asking! How can I assist you today?\"`.\n",
        "\n",
        "What if we mention the words `\"ask lex\"`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkgKG1x3ndBJ",
        "outputId": "369ca0ae-fa73-4485-81ae-bcf9c8cdee08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Lex Fridman DB\",\n",
            "    \"action_input\": \"What is the future of AI?\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe future of AI is both exciting and terrifying. Many believe that we are on the path to creating superintelligent AGI systems that will surpass the collective intelligence of the human species by many orders of magnitude. This could lead to innumerable applications that will empower humans to create, to flourish, to escape widespread poverty and suffering, and to succeed in the pursuit of happiness. However, it is also terrifying because of the power that superintelligent AGI wields to destroy human civilization, intentionally or unintentionally. The responsibility of AI systems to help millions of people and the ethical considerations of creating meaningful experiences with systems that are faking it before they make it are critical questions that need to be addressed. The development of AGI is a dream for many, but there are concerns about the different trajectories that path would take, including existential threats. The digital world provides a frictionless environment for AI systems to operate with much more power, which could lead to destructive outcomes. Overall, the future of AI is uncertain, and we need to carefully consider the implications of its development.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"I'm sorry, but I don't have any record of your last comment. Could you please repeat it?\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'ask lex about the future of ai',\n",
              " 'chat_history': [HumanMessage(content='hi how are you', additional_kwargs={}),\n",
              "  AIMessage(content=\"I'm just a chatbot, so I don't have feelings, but I'm here to help you with any questions you have!\", additional_kwargs={})],\n",
              " 'output': \"I'm sorry, but I don't have any record of your last comment. Could you please repeat it?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "conversational_agent(\"ask lex about the future of ai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dcGpHZSXs2Z"
      },
      "source": [
        "Great, we can see that the first thing the agent did was default to the `\"Lex Fridman DB\"` tool. The input to that tool was generated by the LLM, and is `\"What did Lex Fridman say about the future of AI?\"`.\n",
        "\n",
        "This input is then passed into the `Lex Fridman DB` tool and the output observation of the LLM (after it has read all of the information returned by our vector DB is returned to our agent. From this observation the agent moves on to the `\"Final Answer\"` action, giving us the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvmK5lnzDgU4",
        "outputId": "20a27583-eae9-439d-f031-e0f6d6e72a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Lex Fridman DB\",\n",
            "    \"action_input\": \"What does Lex Fridman think about space exploration?\"\n",
            "}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mLex Fridman believes that space exploration is a beautiful idea and that humans are explorers by nature. He also agrees with Elon Musk's pragmatic view that becoming a multi-planetary species is necessary for our long-term survival. Lex is excited about the possibility of going to Mars, colonizing it, and exploring outside the solar system. He believes that space exploration can inspire people and lead to scientific breakthroughs.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Lex Fridman believes that space exploration is a beautiful idea and that humans are explorers by nature. He also agrees with Elon Musk's pragmatic view that becoming a multi-planetary species is necessary for our long-term survival. Lex is excited about the possibility of going to Mars, colonizing it, and exploring outside the solar system. He believes that space exploration can inspire people and lead to scientific breakthroughs.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what does he think about space exploration?',\n",
              " 'chat_history': [HumanMessage(content='hi how are you', additional_kwargs={}),\n",
              "  AIMessage(content=\"I'm just a chatbot, so I don't have feelings, but I'm here to help you with any questions you have!\", additional_kwargs={}),\n",
              "  HumanMessage(content='ask lex about the future of ai', additional_kwargs={}),\n",
              "  AIMessage(content=\"I'm sorry, but I don't have any record of your last comment. Could you please repeat it?\", additional_kwargs={})],\n",
              " 'output': \"Lex Fridman believes that space exploration is a beautiful idea and that humans are explorers by nature. He also agrees with Elon Musk's pragmatic view that becoming a multi-planetary species is necessary for our long-term survival. Lex is excited about the possibility of going to Mars, colonizing it, and exploring outside the solar system. He believes that space exploration can inspire people and lead to scientific breakthroughs.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "conversational_agent(\"what does he think about space exploration?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e87699c385784c85854e1054b5968571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a9c499bf327431b901e0b5e0a550216",
              "IPY_MODEL_0695335820ce455180bd419e07dcf5db",
              "IPY_MODEL_d88f2f2b43ab4d2a8d771fa79150e825"
            ],
            "layout": "IPY_MODEL_bebf96067c4b4c0c89fe48ffd298af2e"
          }
        },
        "5a9c499bf327431b901e0b5e0a550216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99285af984a148468958a98d3094ea7c",
            "placeholder": "​",
            "style": "IPY_MODEL_fd11657b1bf34070a4cd3cf8ae91b061",
            "value": "Downloading data files: 100%"
          }
        },
        "0695335820ce455180bd419e07dcf5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b7cf8aa612d451b81422614ed7d3573",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a2d157e6eaf4e6791d09393d88717a2",
            "value": 1
          }
        },
        "d88f2f2b43ab4d2a8d771fa79150e825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cee9c02a0d64f34b3658bee64ab7c85",
            "placeholder": "​",
            "style": "IPY_MODEL_20cfb511a75248f39c1b2c55ec0171b4",
            "value": " 1/1 [00:01&lt;00:00,  1.77s/it]"
          }
        },
        "bebf96067c4b4c0c89fe48ffd298af2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99285af984a148468958a98d3094ea7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd11657b1bf34070a4cd3cf8ae91b061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b7cf8aa612d451b81422614ed7d3573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a2d157e6eaf4e6791d09393d88717a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cee9c02a0d64f34b3658bee64ab7c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20cfb511a75248f39c1b2c55ec0171b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c486860f3e9c4bd89cb1248e4baf1487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34064b2e313d4c41abe7cd97822753f2",
              "IPY_MODEL_6e8b276542014087aeedbc110f0765ab",
              "IPY_MODEL_a98951120f8b49e09d813e209d1a06d2"
            ],
            "layout": "IPY_MODEL_ff7b73999de747ca9c76b8513536a7f8"
          }
        },
        "34064b2e313d4c41abe7cd97822753f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf7c349b573426886af0f0d10b1d7a8",
            "placeholder": "​",
            "style": "IPY_MODEL_08122c715c4f4d4d916b6869fc118558",
            "value": "Downloading data: 100%"
          }
        },
        "6e8b276542014087aeedbc110f0765ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae4c73f09f70440784ece901c8c65bc6",
            "max": 44308455,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a125807e11145a6826d2f3f51ecc7e9",
            "value": 44308455
          }
        },
        "a98951120f8b49e09d813e209d1a06d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c796affa0a76436e854c1504c427fcdd",
            "placeholder": "​",
            "style": "IPY_MODEL_1880b4cf87ac48249f349df9eaa24849",
            "value": " 44.3M/44.3M [00:00&lt;00:00, 58.3MB/s]"
          }
        },
        "ff7b73999de747ca9c76b8513536a7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf7c349b573426886af0f0d10b1d7a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08122c715c4f4d4d916b6869fc118558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae4c73f09f70440784ece901c8c65bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a125807e11145a6826d2f3f51ecc7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c796affa0a76436e854c1504c427fcdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1880b4cf87ac48249f349df9eaa24849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "939daffe13fa4204996d2ce759cb5a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73639e72818450ca867dfea800f5dc6",
              "IPY_MODEL_9c58f8c8f4244a868ceba8ef78063745",
              "IPY_MODEL_f249a856c07e48738299bd2c4b2839ac"
            ],
            "layout": "IPY_MODEL_0bb226ac54a24992aa9a9fddab821737"
          }
        },
        "a73639e72818450ca867dfea800f5dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3507c643f74c219f4f27c59a06e1a6",
            "placeholder": "​",
            "style": "IPY_MODEL_462e2d82704c46fab99be483e1aa8093",
            "value": "Extracting data files: 100%"
          }
        },
        "9c58f8c8f4244a868ceba8ef78063745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7faea7f7337449f186a1ff6105fda39a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b34785bb93a44c81b621553f54f4a64d",
            "value": 1
          }
        },
        "f249a856c07e48738299bd2c4b2839ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af9e0f7596c4b87877b730a3d074279",
            "placeholder": "​",
            "style": "IPY_MODEL_725019bcae14422b9b3542fcd52901db",
            "value": " 1/1 [00:00&lt;00:00, 42.71it/s]"
          }
        },
        "0bb226ac54a24992aa9a9fddab821737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3507c643f74c219f4f27c59a06e1a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "462e2d82704c46fab99be483e1aa8093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7faea7f7337449f186a1ff6105fda39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34785bb93a44c81b621553f54f4a64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5af9e0f7596c4b87877b730a3d074279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725019bcae14422b9b3542fcd52901db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2fb2ac93f23460c809ffb46db60911f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1bac7841234d62ad0826c6153d6f3c",
              "IPY_MODEL_760679f729ee4270aec5cf59796ef7b0",
              "IPY_MODEL_4630fe01eaf74fbdb68a63051fb1b15b"
            ],
            "layout": "IPY_MODEL_55ec47746e5c467f97de8fc33afb09e8"
          }
        },
        "7c1bac7841234d62ad0826c6153d6f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cada6880d46a4e06b61960d511a6eedd",
            "placeholder": "​",
            "style": "IPY_MODEL_4ff4eec0986246a8a4b38caf6f76e963",
            "value": "Generating train split: "
          }
        },
        "760679f729ee4270aec5cf59796ef7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5a697ce41a45fd9bedb783127aeae0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70cda74457054f9cab1e78f6880267fd",
            "value": 1
          }
        },
        "4630fe01eaf74fbdb68a63051fb1b15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65bf96b0718245519038e19fd548f161",
            "placeholder": "​",
            "style": "IPY_MODEL_bca21b90d06e423c85587280747854cb",
            "value": " 476/0 [00:00&lt;00:00, 1206.54 examples/s]"
          }
        },
        "55ec47746e5c467f97de8fc33afb09e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "cada6880d46a4e06b61960d511a6eedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff4eec0986246a8a4b38caf6f76e963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a5a697ce41a45fd9bedb783127aeae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "70cda74457054f9cab1e78f6880267fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65bf96b0718245519038e19fd548f161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bca21b90d06e423c85587280747854cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be88b55eb0d9440897d10bf20942248f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6411033f2f341c58711f959d745f1db",
              "IPY_MODEL_ea1e5c07ab1440b8a9fd5ee0d93b9683",
              "IPY_MODEL_0ef2acfbf7094bee8e24b00b4b8fc017"
            ],
            "layout": "IPY_MODEL_3e7c7d154a024fccba4b2c1ca3a83766"
          }
        },
        "d6411033f2f341c58711f959d745f1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f123fa8d7fa4997a867509f74700d9c",
            "placeholder": "​",
            "style": "IPY_MODEL_5fce9695eeb24ee385aa908345e02f3b",
            "value": "100%"
          }
        },
        "ea1e5c07ab1440b8a9fd5ee0d93b9683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b8dde14b3d142778db150e58af5e9b6",
            "max": 499,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1640ac698e204533b25f385549a2d037",
            "value": 499
          }
        },
        "0ef2acfbf7094bee8e24b00b4b8fc017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a49ced78ae4b168d1679ea9a02a3bc",
            "placeholder": "​",
            "style": "IPY_MODEL_977462f15f1d4c27a3270c2b7c9f4fc4",
            "value": " 499/499 [00:40&lt;00:00, 22.59it/s]"
          }
        },
        "3e7c7d154a024fccba4b2c1ca3a83766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f123fa8d7fa4997a867509f74700d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fce9695eeb24ee385aa908345e02f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b8dde14b3d142778db150e58af5e9b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1640ac698e204533b25f385549a2d037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62a49ced78ae4b168d1679ea9a02a3bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977462f15f1d4c27a3270c2b7c9f4fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eab50425900f483dbef0cb6bd6dafead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_065b9a3097e34345a35d2e8a7619e2ee",
              "IPY_MODEL_c874185706134ceb9157fe1329f8d9f8",
              "IPY_MODEL_617bd3409ca945fa83425406578c8ba2"
            ],
            "layout": "IPY_MODEL_2219b3e11ce644468d57655895bef37a"
          }
        },
        "065b9a3097e34345a35d2e8a7619e2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0867a1f242bb465a8df0d459d35a33e1",
            "placeholder": "​",
            "style": "IPY_MODEL_6205d5a2e2804a1e9a9d78d94afb4d00",
            "value": "100%"
          }
        },
        "c874185706134ceb9157fe1329f8d9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6dcf823e58345839271b90b42b66565",
            "max": 362,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20264f594aaa4f00aa3f03b3888b1e2e",
            "value": 362
          }
        },
        "617bd3409ca945fa83425406578c8ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06ca00714734a9e96abaf6795577a7a",
            "placeholder": "​",
            "style": "IPY_MODEL_dc854970983741819915a88bb8254bde",
            "value": " 362/362 [07:59&lt;00:00,  1.37s/it]"
          }
        },
        "2219b3e11ce644468d57655895bef37a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0867a1f242bb465a8df0d459d35a33e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6205d5a2e2804a1e9a9d78d94afb4d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6dcf823e58345839271b90b42b66565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20264f594aaa4f00aa3f03b3888b1e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a06ca00714734a9e96abaf6795577a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc854970983741819915a88bb8254bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}